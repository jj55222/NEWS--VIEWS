{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FOIA-Free Content Pipeline — Colab Runner\n",
    "\n",
    "Run the full pipeline from Google Colab.  \n",
    "Set your API keys in the cells below, then run each stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Install dependencies\n",
    "!pip install -q pyyaml python-dotenv openai requests feedparser beautifulsoup4 yt-dlp\n",
    "!apt-get -qq install -y ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 2. Clone repo and set up Python path\nimport os, sys\n\nREPO_URL = 'https://github.com/jj55222/NEWS--VIEWS.git'\nBRANCH = 'claude/foia-free-content-pipeline-qlbzp'\nREPO_DIR = '/content/NEWS--VIEWS'\n\n# Clone the correct branch if not already present\nif not os.path.isdir(REPO_DIR):\n    !git clone -b {BRANCH} {REPO_URL} {REPO_DIR}\n\n# Always use absolute path to avoid double-chdir issues on re-run\nos.chdir(REPO_DIR)\n\n# Add to Python path so \"from scripts...\" imports work\nif REPO_DIR not in sys.path:\n    sys.path.insert(0, REPO_DIR)\n\nprint('Working directory:', os.getcwd())\nprint('scripts/ exists:', os.path.isdir('scripts'))\nprint('config/ exists:', os.path.isdir('config'))"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 3. Set API keys\nimport os\n\n# REQUIRED: Set your API keys here\nos.environ['OPENROUTER_API_KEY'] = ''  # Your OpenRouter API key\nos.environ['YOUTUBE_API_KEY'] = ''     # Your YouTube Data API v3 key\nos.environ['BRAVE_API_KEY'] = ''       # Your Brave Search API key (https://brave.com/search/api/)\n\nprint('API keys configured.' if os.environ.get('OPENROUTER_API_KEY') else 'WARNING: Set API keys above!')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# 4. Initialize database\nimport sys, os\n\n# Safety net: ensure project root is on path even if cell 2 was skipped/stale\nREPO_DIR = '/content/NEWS--VIEWS'\nif os.path.isdir(REPO_DIR):\n    os.chdir(REPO_DIR)\n    if REPO_DIR not in sys.path:\n        sys.path.insert(0, REPO_DIR)\n\nfrom scripts.db import init_db\nfrom scripts.config_loader import ensure_dirs, load_policy, load_sources\n\nensure_dirs()\ninit_db()\n\npolicy = load_policy()\nsources = load_sources()\nprint(f'Policy: {len(policy)} sections')\nprint(f'Sources: {len(sources)} feeds ({len([s for s in sources if s.get(\"enabled\")])} enabled)')"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5a. INGEST — Pull new candidates (YouTube + RSS + pages)\n",
    "from scripts.run_pipeline import run_ingest\n",
    "\n",
    "ingest_results = run_ingest(days=7, dry_run=False)\n",
    "ingest_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5b. ENRICH — Add transcripts and entities\n",
    "from scripts.run_pipeline import run_enrich\n",
    "\n",
    "enrich_results = run_enrich(limit=200, dry_run=False)\n",
    "enrich_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5c. TRIAGE — Score and classify candidates\n",
    "from scripts.run_pipeline import run_triage\n",
    "\n",
    "triage_results = run_triage(limit=200, dry_run=False)\n",
    "triage_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Review PASS candidates\n",
    "from scripts.db import get_connection, get_candidates\n",
    "import json\n",
    "\n",
    "conn = get_connection()\n",
    "pass_candidates = get_candidates(conn, status='PASS', limit=50)\n",
    "print(f'PASS candidates: {len(pass_candidates)}')\n",
    "print()\n",
    "\n",
    "for i, c in enumerate(pass_candidates[:20], 1):\n",
    "    print(f'{i:2d}. [{c[\"triage_score\"]:3d}] {c[\"title\"][:80]}')\n",
    "    print(f'    Type: {c[\"incident_type\"]} | URL: {c[\"url\"]}')\n",
    "    print(f'    Reason: {(c.get(\"triage_rationale\") or \"\")[:100]}')\n",
    "    print()\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 7. CORROBORATE — Gather supporting sources for PASS candidates\n",
    "from scripts.run_pipeline import run_corroborate\n",
    "\n",
    "corr_results = run_corroborate(limit=20, dry_run=False)\n",
    "corr_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 8. PACKAGE — Build case bundles (timeline, narration, shorts plan)\n",
    "from scripts.run_pipeline import run_package\n",
    "\n",
    "package_results = run_package(limit=5, dry_run=False)\n",
    "package_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 9. RENDER — Download, cut, caption, export\n",
    "from scripts.run_pipeline import run_render\n",
    "\n",
    "render_results = run_render(limit=3, dry_run=False)\n",
    "render_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 10. Pipeline stats\n",
    "from scripts.db import get_connection\n",
    "\n",
    "conn = get_connection()\n",
    "print('=== Pipeline Stats ===')\n",
    "for table in ['candidates', 'cases', 'corroboration_sources']:\n",
    "    count = conn.execute(f'SELECT COUNT(*) FROM {table}').fetchone()[0]\n",
    "    print(f'  {table}: {count} rows')\n",
    "\n",
    "print()\n",
    "print('Triage distribution:')\n",
    "for status in ['NEW', 'PASS', 'MAYBE', 'KILL']:\n",
    "    count = conn.execute(\n",
    "        'SELECT COUNT(*) FROM candidates WHERE triage_status = ?', (status,)\n",
    "    ).fetchone()[0]\n",
    "    print(f'  {status}: {count}')\n",
    "\n",
    "print()\n",
    "print('Case status distribution:')\n",
    "for status in ['APPROVED', 'PACKAGED', 'RENDERED', 'READY_TO_PUBLISH']:\n",
    "    count = conn.execute(\n",
    "        'SELECT COUNT(*) FROM cases WHERE status = ?', (status,)\n",
    "    ).fetchone()[0]\n",
    "    if count > 0:\n",
    "        print(f'  {status}: {count}')\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FULL PIPELINE (single command)\n",
    "# Uncomment and run this to execute the entire pipeline at once:\n",
    "\n",
    "# from scripts.run_pipeline import run_pipeline\n",
    "# results = run_pipeline(days=7, dry_run=False)\n",
    "# results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}